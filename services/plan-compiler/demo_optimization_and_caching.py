#!/usr/bin/env python3
"""
Demo script showcasing Plan Optimization and Caching functionality.

This script demonstrates:
1. ExecutablePlan caching by plan_hash
2. Plan optimization for performance
3. Plan dependency graph analysis
4. Plan execution cost estimation
"""

import asyncio
import time
from uuid import uuid4
from datetime import datetime

from src.models import ExecutablePlan, ExecutionFlow, ExecutionStep, PlanMetadata, CompilationRequest
from src.compiler import PlanCompiler, CapsuleDefinition
from src.optimizer import PlanOptimizer
from src.dependency_analyzer import DependencyAnalyzer
from src.cache_service import PlanCacheService, CacheConfig


async def create_sample_capsule() -> CapsuleDefinition:
    """Create a sample capsule for demonstration."""
    
    return CapsuleDefinition(
        name="data_processing_workflow",
        version="2.1.0",
        description="Data processing workflow with multiple steps",
        automation={
            "workflow": {
                "name": "Data Processing",
                "description": "End-to-end data processing with validation and transformation",
                "steps": [
                    {
                        "id": "fetch_data",
                        "name": "Fetch Data",
                        "type": "action",
                        "action": "fetch",
                        "tool": "database",
                        "parameters": {
                            "table": "raw_data",
                            "limit": 1000
                        },
                        "outputs": {"raw_data": "fetched_data"}
                    },
                    {
                        "id": "validate_data",
                        "name": "Validate Data",
                        "type": "action",
                        "action": "validate",
                        "tool": "compute",
                        "inputs": {"data": "fetched_data"},
                        "depends_on": ["fetch_data"],
                        "parameters": {
                            "schema": "data_schema_v2"
                        },
                        "outputs": {"validation_result": "validated_data"}
                    },
                    {
                        "id": "transform_data",
                        "name": "Transform Data",
                        "type": "action",
                        "action": "transform",
                        "tool": "compute",
                        "inputs": {"data": "validated_data"},
                        "depends_on": ["validate_data"],
                        "parameters": {
                            "format": "json",
                            "normalize": True
                        },
                        "outputs": {"transformed_data": "processed_data"}
                    },
                    {
                        "id": "enrich_data",
                        "name": "Enrich Data",
                        "type": "action",
                        "action": "enrich",
                        "tool": "http",
                        "inputs": {"data": "validated_data"},
                        "depends_on": ["validate_data"],
                        "parameters": {
                            "api_endpoint": "/enrich",
                            "timeout": 30
                        },
                        "outputs": {"enriched_data": "enrichment_result"}
                    },
                    {
                        "id": "merge_results",
                        "name": "Merge Results",
                        "type": "action",
                        "action": "merge",
                        "tool": "compute",
                        "inputs": {
                            "transformed": "processed_data",
                            "enriched": "enrichment_result"
                        },
                        "depends_on": ["transform_data", "enrich_data"],
                        "parameters": {
                            "strategy": "left_join"
                        },
                        "outputs": {"final_data": "merged_result"}
                    },
                    {
                        "id": "store_results",
                        "name": "Store Results",
                        "type": "action",
                        "action": "store",
                        "tool": "database",
                        "inputs": {"data": "merged_result"},
                        "depends_on": ["merge_results"],
                        "parameters": {
                            "table": "processed_data",
                            "batch_size": 100
                        }
                    },
                    {
                        "id": "send_notification",
                        "name": "Send Notification",
                        "type": "action",
                        "action": "notify",
                        "tool": "http",
                        "inputs": {"summary": "merged_result"},
                        "depends_on": ["store_results"],
                        "parameters": {
                            "webhook_url": "/notifications",
                            "format": "summary"
                        }
                    }
                ]
            }
        },
        tools=[
            "database",
            "compute", 
            "http"
        ],
        policies=[],
        dependencies=[]
    )


async def demo_dependency_analysis():
    """Demonstrate dependency graph analysis."""
    
    print("\n" + "="*60)
    print("üîç DEPENDENCY ANALYSIS DEMO")
    print("="*60)
    
    # Create analyzer
    analyzer = DependencyAnalyzer()
    
    # Create sample capsule and compile to plan
    capsule = await create_sample_capsule()
    compiler = PlanCompiler()
    
    tenant_id = uuid4()
    user_id = uuid4()
    
    compilation_request = CompilationRequest(
        capsule_id=uuid4(),
        optimization_level="none",  # No optimization for pure analysis
        cache_result=False,
        validate_dependencies=False  # Skip dependency validation for demo
    )
    
    print(f"üìã Compiling capsule: {capsule.name} v{capsule.version}")
    result = await compiler.compile_capsule(capsule, tenant_id, user_id, compilation_request)
    
    if not result.success:
        print(f"‚ùå Compilation failed: {result.errors}")
        return
    
    plan = result.plan
    print(f"‚úÖ Plan compiled successfully: {plan.plan_hash[:16]}...")
    
    # Perform dependency analysis
    print(f"\nüî¨ Analyzing plan dependencies...")
    start_time = time.time()
    
    analysis = await analyzer.analyze_plan_dependencies(plan)
    
    analysis_time = time.time() - start_time
    
    # Display results
    print(f"‚è±Ô∏è  Analysis completed in {analysis_time:.3f} seconds")
    print(f"\nüìä ANALYSIS RESULTS:")
    print(f"   ‚Ä¢ Graph nodes (steps): {analysis.graph.number_of_nodes()}")
    print(f"   ‚Ä¢ Graph edges (dependencies): {analysis.graph.number_of_edges()}")
    print(f"   ‚Ä¢ Critical paths found: {len(analysis.critical_paths)}")
    print(f"   ‚Ä¢ Parallelization opportunities: {len(analysis.parallelization_opportunities)}")
    print(f"   ‚Ä¢ Execution levels: {len(analysis.execution_levels)}")
    print(f"   ‚Ä¢ Total estimated duration: {analysis.total_estimated_duration:.1f} seconds")
    print(f"   ‚Ä¢ Total estimated cost: ${analysis.total_estimated_cost:.4f}")
    
    # Show complexity metrics
    print(f"\nüìà COMPLEXITY METRICS:")
    for metric, value in analysis.complexity_metrics.items():
        print(f"   ‚Ä¢ {metric}: {value:.3f}")
    
    # Show critical path details
    if analysis.critical_paths:
        longest_path = max(analysis.critical_paths, key=lambda p: p.total_duration)
        print(f"\nüéØ CRITICAL PATH (longest):")
        print(f"   ‚Ä¢ Steps: {' ‚Üí '.join(longest_path.steps)}")
        print(f"   ‚Ä¢ Duration: {longest_path.total_duration:.1f} seconds")
        print(f"   ‚Ä¢ Cost: ${longest_path.total_cost:.4f}")
        print(f"   ‚Ä¢ Bottlenecks: {longest_path.bottlenecks}")
    
    # Show parallelization opportunities
    if analysis.parallelization_opportunities:
        print(f"\n‚ö° PARALLELIZATION OPPORTUNITIES:")
        for i, opp in enumerate(analysis.parallelization_opportunities):
            print(f"   {i+1}. Steps: {opp.parallel_steps}")
            print(f"      Estimated speedup: {opp.estimated_speedup:.1f}x")
            if opp.constraints:
                print(f"      Constraints: {opp.constraints}")
    
    # Show optimization recommendations
    if analysis.optimization_recommendations:
        print(f"\nüí° OPTIMIZATION RECOMMENDATIONS:")
        for i, rec in enumerate(analysis.optimization_recommendations):
            print(f"   {i+1}. {rec}")
    
    return analysis


async def demo_plan_optimization():
    """Demonstrate plan optimization."""
    
    print("\n" + "="*60)
    print("‚ö° PLAN OPTIMIZATION DEMO")
    print("="*60)
    
    # Create optimizer
    optimizer = PlanOptimizer()
    
    # Create sample capsule and compile to plan
    capsule = await create_sample_capsule()
    compiler = PlanCompiler()
    
    tenant_id = uuid4()
    user_id = uuid4()
    
    compilation_request = CompilationRequest(
        capsule_id=uuid4(),
        optimization_level="none",  # Start with no optimization
        cache_result=False,
        validate_dependencies=False  # Skip dependency validation for demo
    )
    
    print(f"üìã Compiling unoptimized plan...")
    result = await compiler.compile_capsule(capsule, tenant_id, user_id, compilation_request)
    original_plan = result.plan
    
    print(f"‚úÖ Original plan: {original_plan.plan_hash[:16]}...")
    
    # Test different optimization levels
    optimization_levels = ["basic", "standard", "aggressive"]
    optimization_results = {}
    
    for level in optimization_levels:
        print(f"\nüîß Applying {level} optimization...")
        start_time = time.time()
        
        optimized_plan = await optimizer.optimize_plan(original_plan, level)
        
        optimization_time = time.time() - start_time
        optimization_results[level] = {
            "plan": optimized_plan,
            "time": optimization_time
        }
        
        print(f"   ‚è±Ô∏è  Optimization time: {optimization_time:.3f} seconds")
        print(f"   üÜî Optimized hash: {optimized_plan.plan_hash[:16]}...")
        print(f"   üìä Estimated duration: {optimized_plan.metadata.estimated_duration} seconds")
        print(f"   üí∞ Estimated cost: ${optimized_plan.metadata.estimated_cost}")
        print(f"   üìù Optimization notes: {len(optimized_plan.metadata.optimization_notes)} items")
    
    # Compare optimization results
    print(f"\nüìä OPTIMIZATION COMPARISON:")
    print(f"{'Level':<12} {'Duration':<10} {'Cost':<10} {'Time':<8} {'Notes'}")
    print("-" * 50)
    
    # Original plan
    print(f"{'Original':<12} {'N/A':<10} {'N/A':<10} {'N/A':<8} {0}")
    
    for level in optimization_levels:
        result = optimization_results[level]
        plan = result["plan"]
        duration = plan.metadata.estimated_duration or 0
        cost = plan.metadata.estimated_cost or 0
        opt_time = result["time"]
        notes = len(plan.metadata.optimization_notes)
        
        print(f"{level:<12} {duration:<10.1f} ${cost:<9.4f} {opt_time:<8.3f} {notes}")
    
    # Show optimization caching
    print(f"\nüíæ Testing optimization caching...")
    start_time = time.time()
    cached_plan = await optimizer.optimize_plan(original_plan, "aggressive")
    cache_time = time.time() - start_time
    
    print(f"   ‚ö° Cached optimization time: {cache_time:.3f} seconds")
    print(f"   ‚úÖ Cache hit: {cache_time < 0.01}")  # Should be very fast if cached
    
    return optimization_results


async def demo_plan_caching():
    """Demonstrate plan caching functionality."""
    
    print("\n" + "="*60)
    print("üíæ PLAN CACHING DEMO")
    print("="*60)
    
    # Create cache service with custom config
    cache_config = CacheConfig(
        max_entries=100,
        max_size_bytes=10 * 1024 * 1024,  # 10MB
        default_ttl_hours=2,
        cleanup_interval_minutes=5
    )
    
    cache_service = PlanCacheService(cache_config)
    
    # Create multiple plans for caching
    plans = []
    tenant_id = uuid4()
    
    print(f"üèóÔ∏è  Creating sample plans...")
    
    for i in range(5):
        capsule = await create_sample_capsule()
        capsule.name = f"workflow_{i+1}"
        capsule.version = f"1.{i}.0"
        
        compiler = PlanCompiler()
        user_id = uuid4()
        
        compilation_request = CompilationRequest(
            capsule_id=uuid4(),
            optimization_level="standard",
            cache_result=False,  # We'll cache manually for demo
            validate_dependencies=False  # Skip dependency validation for demo
        )
        
        result = await compiler.compile_capsule(capsule, tenant_id, user_id, compilation_request)
        if result.success:
            plans.append(result.plan)
            print(f"   ‚úÖ Plan {i+1}: {result.plan.plan_hash[:16]}...")
    
    # Cache all plans
    print(f"\nüíæ Caching {len(plans)} plans...")
    
    for i, plan in enumerate(plans):
        tags = [f"workflow_{i+1}", "demo", "cached"]
        success = await cache_service.put(plan, tags=tags)
        print(f"   {'‚úÖ' if success else '‚ùå'} Cached plan {i+1}")
    
    # Test cache retrieval
    print(f"\nüîç Testing cache retrieval...")
    
    cache_hits = 0
    cache_misses = 0
    
    for i, plan in enumerate(plans):
        start_time = time.time()
        retrieved = await cache_service.get(plan.plan_hash, tenant_id)
        retrieval_time = time.time() - start_time
        
        if retrieved:
            cache_hits += 1
            print(f"   ‚úÖ Cache HIT for plan {i+1} ({retrieval_time:.4f}s)")
        else:
            cache_misses += 1
            print(f"   ‚ùå Cache MISS for plan {i+1}")
    
    # Test tenant isolation
    print(f"\nüîí Testing tenant isolation...")
    different_tenant = uuid4()
    
    for i, plan in enumerate(plans[:2]):  # Test first 2 plans
        retrieved = await cache_service.get(plan.plan_hash, different_tenant)
        if retrieved:
            print(f"   ‚ùå SECURITY ISSUE: Plan {i+1} accessible to wrong tenant!")
        else:
            print(f"   ‚úÖ Plan {i+1} properly isolated")
    
    # Show cache statistics
    print(f"\nüìä Cache statistics:")
    stats = await cache_service.get_stats()
    
    print(f"   ‚Ä¢ Total entries: {stats.total_entries}")
    print(f"   ‚Ä¢ Cache hits: {stats.hit_count}")
    print(f"   ‚Ä¢ Cache misses: {stats.miss_count}")
    print(f"   ‚Ä¢ Hit ratio: {stats.hit_ratio:.2%}")
    print(f"   ‚Ä¢ Total size: {stats.total_size_bytes:,} bytes")
    print(f"   ‚Ä¢ Average access time: {stats.average_access_time:.4f}s")
    
    # Test cache invalidation
    print(f"\nüóëÔ∏è  Testing cache invalidation...")
    
    # Invalidate by tag
    invalidated = await cache_service.invalidate_by_tag("demo")
    print(f"   ‚úÖ Invalidated {invalidated} plans by tag 'demo'")
    
    # Verify invalidation
    remaining_stats = await cache_service.get_stats()
    print(f"   üìä Remaining entries: {remaining_stats.total_entries}")
    
    await cache_service.shutdown()
    
    return {
        "total_plans": len(plans),
        "cache_hits": cache_hits,
        "cache_misses": cache_misses,
        "hit_ratio": cache_hits / len(plans) if plans else 0
    }


async def demo_integrated_compilation():
    """Demonstrate integrated compilation with caching and optimization."""
    
    print("\n" + "="*60)
    print("üîÑ INTEGRATED COMPILATION DEMO")
    print("="*60)
    
    # Create compiler
    compiler = PlanCompiler()
    
    # Create sample capsule
    capsule = await create_sample_capsule()
    tenant_id = uuid4()
    user_id = uuid4()
    
    # Test compilation with different settings
    compilation_scenarios = [
        {
            "name": "Basic Compilation",
            "optimization_level": "none",
            "cache_result": False
        },
        {
            "name": "Optimized Compilation",
            "optimization_level": "aggressive",
            "cache_result": True
        },
        {
            "name": "Cached Compilation",
            "optimization_level": "aggressive",
            "cache_result": True
        }
    ]
    
    results = {}
    
    for scenario in compilation_scenarios:
        print(f"\nüß™ Testing: {scenario['name']}")
        
        request = CompilationRequest(
            capsule_id=uuid4(),
            optimization_level=scenario["optimization_level"],
            cache_result=scenario["cache_result"],
            validate_dependencies=False  # Skip dependency validation for demo
        )
        
        start_time = time.time()
        result = await compiler.compile_capsule(capsule, tenant_id, user_id, request)
        compilation_time = time.time() - start_time
        
        if result.success:
            plan = result.plan
            print(f"   ‚úÖ Success in {compilation_time:.3f}s")
            print(f"   üÜî Plan hash: {plan.plan_hash[:16]}...")
            print(f"   ‚ö° Optimization: {plan.metadata.optimization_level}")
            print(f"   üìä Duration: {plan.metadata.estimated_duration}s")
            print(f"   üí∞ Cost: ${plan.metadata.estimated_cost}")
            print(f"   üìù Notes: {len(plan.metadata.optimization_notes)} optimization notes")
            
            results[scenario["name"]] = {
                "success": True,
                "time": compilation_time,
                "plan_hash": plan.plan_hash,
                "duration": plan.metadata.estimated_duration,
                "cost": plan.metadata.estimated_cost
            }
        else:
            print(f"   ‚ùå Failed: {result.errors}")
            results[scenario["name"]] = {
                "success": False,
                "time": compilation_time,
                "errors": result.errors
            }
    
    # Show performance comparison
    print(f"\nüìä PERFORMANCE COMPARISON:")
    print(f"{'Scenario':<20} {'Time (s)':<10} {'Duration':<10} {'Cost'}")
    print("-" * 55)
    
    for name, result in results.items():
        if result["success"]:
            time_str = f"{result['time']:.3f}"
            duration_str = f"{result['duration']:.1f}" if result['duration'] else "N/A"
            cost_str = f"${result['cost']:.4f}" if result['cost'] else "N/A"
            print(f"{name:<20} {time_str:<10} {duration_str:<10} {cost_str}")
        else:
            print(f"{name:<20} {'FAILED':<10} {'N/A':<10} {'N/A'}")
    
    return results


async def main():
    """Run all demos."""
    
    print("üöÄ PLAN COMPILER OPTIMIZATION & CACHING DEMO")
    print("=" * 60)
    print("This demo showcases the implementation of task A.12:")
    print("‚Ä¢ ExecutablePlan caching by plan_hash")
    print("‚Ä¢ Plan optimization for performance") 
    print("‚Ä¢ Plan dependency graph analysis")
    print("‚Ä¢ Plan execution cost estimation")
    
    try:
        # Run all demos
        dependency_analysis = await demo_dependency_analysis()
        optimization_results = await demo_plan_optimization()
        caching_results = await demo_plan_caching()
        integration_results = await demo_integrated_compilation()
        
        # Summary
        print("\n" + "="*60)
        print("üìã DEMO SUMMARY")
        print("="*60)
        
        print(f"‚úÖ Dependency Analysis: Analyzed complex workflow with {dependency_analysis.graph.number_of_nodes()} steps")
        print(f"‚úÖ Plan Optimization: Tested 3 optimization levels with cost/duration estimation")
        print(f"‚úÖ Plan Caching: Achieved {caching_results['hit_ratio']:.0%} cache hit ratio")
        print(f"‚úÖ Integrated Compilation: Successfully compiled with caching and optimization")
        
        print(f"\nüéØ KEY ACHIEVEMENTS:")
        print(f"   ‚Ä¢ Dependency graph analysis with {len(dependency_analysis.critical_paths)} critical paths")
        print(f"   ‚Ä¢ {len(dependency_analysis.parallelization_opportunities)} parallelization opportunities identified")
        print(f"   ‚Ä¢ Cost estimation: ${dependency_analysis.total_estimated_cost:.4f}")
        print(f"   ‚Ä¢ Duration estimation: {dependency_analysis.total_estimated_duration:.1f} seconds")
        print(f"   ‚Ä¢ Cache performance: {caching_results['cache_hits']}/{caching_results['total_plans']} hits")
        print(f"   ‚Ä¢ Optimization caching working correctly")
        
        print(f"\n‚ú® Task A.12 implementation is complete and fully functional!")
        
    except Exception as e:
        print(f"\n‚ùå Demo failed with error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())